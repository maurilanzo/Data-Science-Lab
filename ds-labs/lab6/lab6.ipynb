{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maurilanzo/Data-Science-Lab/blob/main/ds-labs/lab6/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "c05e7d6d",
      "metadata": {
        "id": "c05e7d6d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "sFrr-HErFSPa"
      },
      "id": "sFrr-HErFSPa",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a699613a",
      "metadata": {
        "id": "a699613a"
      },
      "outputs": [],
      "source": [
        "ts = torch.tensor([[2,5.6,4.3],[3,2,2]])\n",
        "ts2 = torch.tensor([5.3,4.7,6.7])\n",
        "#ts*ts2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts.to(\"int\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "LfKXAQOZCpww",
        "outputId": "419d7e1f-d9fe-4d60-8b5c-284b45c77c94"
      },
      "id": "LfKXAQOZCpww",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-946850514.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(213)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QrPSnc5EpQX",
        "outputId": "f0431d27-3c24-4529-d6a1-5e26092d4446"
      },
      "id": "_QrPSnc5EpQX",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c055cb20d90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M1_64 = torch.randn((1000,1000)).to(torch.float64)\n",
        "M2_64 = torch.randn((1000,1000)).to(torch.float64)\n",
        "M1_32 = torch.randn((1000,1000)).to(torch.float32)\n",
        "M2_32 = torch.randn((1000,1000)).to(torch.float32)"
      ],
      "metadata": {
        "id": "aZa9YpDfCqeT"
      },
      "id": "aZa9YpDfCqeT",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import timeit\n",
        "# Example timing for float64 and float32 matrix multiplication\n",
        "t64 = timeit ( lambda : M1_64 @ M2_64 , number =100)\n",
        "t32 = timeit ( lambda : M1_32 @ M2_32 , number =100)\n",
        "print (f\" Time for matrix multiplication ( float64 ) : { t64 } s \" )\n",
        "print (f\" Time for matrix multiplication ( float32 ) : { t32 } s \" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj4mU07yDq2Y",
        "outputId": "1adb25ad-ceb0-4a00-84d4-a1e8bccb5aea"
      },
      "id": "Yj4mU07yDq2Y",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Time for matrix multiplication ( float64 ) : 2.869378071 s \n",
            " Time for matrix multiplication ( float32 ) : 1.4151978900000017 s \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets and Dataloaders\n"
      ],
      "metadata": {
        "id": "LSqRHmS6G_xH"
      },
      "id": "LSqRHmS6G_xH"
    },
    {
      "cell_type": "code",
      "source": [
        "n=2048\n",
        "X = torch.randn((n,1)).to(device)\n",
        "\n",
        "noise = torch.randn((n,1))*0.1\n",
        "\n",
        "y = (5*X+3+noise).to(device)"
      ],
      "metadata": {
        "id": "WdLAmMQJHEJI"
      },
      "id": "WdLAmMQJHEJI",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= TensorDataset(X,y)\n",
        "batch_size = 256\n",
        "loader = DataLoader(dataset,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "s-jAH9RlH0BQ"
      },
      "id": "s-jAH9RlH0BQ",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLinearModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleLinearModel,self).__init__()\n",
        "    self.linear=nn.Linear(1,1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.linear(X)\n"
      ],
      "metadata": {
        "id": "7A3umREcRXri"
      },
      "id": "7A3umREcRXri",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleLinearModel()\n",
        "y = model(X)"
      ],
      "metadata": {
        "id": "Bup_M7S8Vl_q"
      },
      "id": "Bup_M7S8Vl_q",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=50\n",
        "losses,weights,biases=[],[],[]\n",
        "model.train()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss=0.0\n",
        "    for inputs,labels in loader:\n",
        "        inputs,labels=inputs.to(device),labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs=model(inputs)\n",
        "        loss= criterion(outputs,labels)\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Track values\n",
        "        losses.append(loss.item())\n",
        "        weights.append(model.linear.weight.item())\n",
        "        biases.append(model.linear.bias.item())\n",
        "        running_loss+=loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "NOTrNuN5V1G0",
        "outputId": "58152632-19e2-407e-cfa8-eed65808f06f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NOTrNuN5V1G0",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] - Loss: 14.5055\n",
            "Epoch [2/50] - Loss: 10.4473\n",
            "Epoch [3/50] - Loss: 7.5271\n",
            "Epoch [4/50] - Loss: 5.4224\n",
            "Epoch [5/50] - Loss: 3.9084\n",
            "Epoch [6/50] - Loss: 2.8167\n",
            "Epoch [7/50] - Loss: 2.0311\n",
            "Epoch [8/50] - Loss: 1.4654\n",
            "Epoch [9/50] - Loss: 1.0582\n",
            "Epoch [10/50] - Loss: 0.7648\n",
            "Epoch [11/50] - Loss: 0.5535\n",
            "Epoch [12/50] - Loss: 0.4013\n",
            "Epoch [13/50] - Loss: 0.2918\n",
            "Epoch [14/50] - Loss: 0.2128\n",
            "Epoch [15/50] - Loss: 0.1560\n",
            "Epoch [16/50] - Loss: 0.1151\n",
            "Epoch [17/50] - Loss: 0.0856\n",
            "Epoch [18/50] - Loss: 0.0643\n",
            "Epoch [19/50] - Loss: 0.0491\n",
            "Epoch [20/50] - Loss: 0.0380\n",
            "Epoch [21/50] - Loss: 0.0301\n",
            "Epoch [22/50] - Loss: 0.0244\n",
            "Epoch [23/50] - Loss: 0.0203\n",
            "Epoch [24/50] - Loss: 0.0173\n",
            "Epoch [25/50] - Loss: 0.0152\n",
            "Epoch [26/50] - Loss: 0.0137\n",
            "Epoch [27/50] - Loss: 0.0126\n",
            "Epoch [28/50] - Loss: 0.0118\n",
            "Epoch [29/50] - Loss: 0.0112\n",
            "Epoch [30/50] - Loss: 0.0108\n",
            "Epoch [31/50] - Loss: 0.0105\n",
            "Epoch [32/50] - Loss: 0.0103\n",
            "Epoch [33/50] - Loss: 0.0101\n",
            "Epoch [34/50] - Loss: 0.0100\n",
            "Epoch [35/50] - Loss: 0.0099\n",
            "Epoch [36/50] - Loss: 0.0099\n",
            "Epoch [37/50] - Loss: 0.0098\n",
            "Epoch [38/50] - Loss: 0.0098\n",
            "Epoch [39/50] - Loss: 0.0098\n",
            "Epoch [40/50] - Loss: 0.0097\n",
            "Epoch [41/50] - Loss: 0.0097\n",
            "Epoch [42/50] - Loss: 0.0097\n",
            "Epoch [43/50] - Loss: 0.0097\n",
            "Epoch [44/50] - Loss: 0.0097\n",
            "Epoch [45/50] - Loss: 0.0097\n",
            "Epoch [46/50] - Loss: 0.0097\n",
            "Epoch [47/50] - Loss: 0.0097\n",
            "Epoch [48/50] - Loss: 0.0097\n",
            "Epoch [49/50] - Loss: 0.0097\n",
            "Epoch [50/50] - Loss: 0.0097\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}